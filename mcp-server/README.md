# MCP Server (Model Context Protocol)

A JSON-RPC 2.0 server built with Rust and Axum that provides AI agent functionality using Google's Gemini API. This server manages multiple specialized AI agents and processes user requests with context-aware responses.

## ğŸ¯ What It Does

The MCP Server is the AI brain of the system:

1. **Manages AI Agents**: Four specialized agents with different expertise
2. **Processes Requests**: Handles JSON-RPC 2.0 protocol for agent interactions
3. **Interfaces with Gemini**: Uses Google's Gemini 2.0 Flash model for AI responses
4. **Provides Context**: Each agent has specialized system instructions
5. **Returns Metadata**: Includes processing stats like tokens used and timing

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP API       â”‚
â”‚  (Port 8000)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ JSON-RPC 2.0
         â”‚ {"method": "process_text", "params": {...}}
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       MCP Server (Port 3000)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Agent Router                      â”‚  â”‚
â”‚  â”‚  - General Assistant (agent_001)   â”‚  â”‚
â”‚  â”‚  - Web3 Expert (agent_002)         â”‚  â”‚
â”‚  â”‚  - Voice Assistant (agent_003)     â”‚  â”‚
â”‚  â”‚  - Code Helper (agent_004)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTPS
         â”‚ POST with system_instruction
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Google Gemini  â”‚
â”‚  gemini-2.0-flashâ”‚
â”‚    -exp (v1beta) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- **JSON-RPC 2.0 Protocol**: Standard protocol for remote procedure calls
- **Multiple AI Agents**: Four specialized agents with unique capabilities
- **Gemini Integration**: Powered by Google's latest Gemini 2.0 model
- **System Instructions**: Each agent has tailored behavior and expertise
- **Metadata Tracking**: Returns tokens used, processing time, and confidence
- **Error Handling**: Comprehensive error responses with details
- **Async Performance**: High-throughput request handling

## ğŸ¤– Available Agents

### Agent 001 - General Assistant
**ID:** `agent_001`  
**Expertise:** General-purpose assistance  
**Best for:** General questions, everyday tasks, broad knowledge queries

### Agent 002 - Web3 Expert
**ID:** `agent_002`  
**Expertise:** Blockchain, cryptocurrency, DeFi, NFTs, smart contracts  
**Best for:** Web3 technology questions, blockchain explanations, crypto advice

### Agent 003 - Voice Assistant
**ID:** `agent_003`  
**Expertise:** Natural conversation, voice interactions  
**Best for:** Conversational responses, audio-based interactions

### Agent 004 - Code Helper
**ID:** `agent_004`  
**Expertise:** Programming, debugging, code review, best practices  
**Best for:** Code questions, bug fixes, architecture advice

## ğŸ“‹ Prerequisites

- **Rust** 1.70 or higher ([Install Rust](https://rustup.rs/))
- **Google Gemini API Key** ([Get your key](https://aistudio.google.com/app/apikey))

## ğŸš€ Quick Start

### 1. Get Your Gemini API Key

1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Click **"Get API Key"** or **"Create API Key"**
3. Copy the generated API key

### 2. Configure Environment

Create a `.env` file in the `mcp-server` directory:

```env
# Google Gemini API Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# Logging Configuration
RUST_LOG=info
```

### 3. Build and Run

```powershell
# Navigate to the directory
cd mcp-server

# Build the project (release mode for production)
cargo build --release

# Run the server
cargo run --release
```

The server will start on `http://127.0.0.1:3000`

### 4. Verify It's Running

```powershell
# List agents
Invoke-RestMethod -Uri "http://localhost:3000" `
  -Method POST `
  -ContentType "application/json" `
  -Body '{
    "jsonrpc": "2.0",
    "method": "list_agents",
    "params": {},
    "id": 1
  }'
```

## ğŸ“¡ JSON-RPC Methods

### Method: `list_agents`

List all available AI agents.

**Request:**
```json
{
  "jsonrpc": "2.0",
  "method": "list_agents",
  "params": {},
  "id": 1
}
```

**Response:**
```json
{
  "jsonrpc": "2.0",
  "result": {
    "agents": [
      {
        "id": "agent_001",
        "name": "General Assistant",
        "description": "A helpful general-purpose AI assistant",
        "model": "gemini-2.0-flash-exp"
      },
      {
        "id": "agent_002",
        "name": "Web3 Expert",
        "description": "Specialized in blockchain, cryptocurrency, and Web3 technologies",
        "model": "gemini-2.0-flash-exp"
      },
      {
        "id": "agent_003",
        "name": "Voice Assistant",
        "description": "Optimized for voice interactions and conversational responses",
        "model": "gemini-2.0-flash-exp"
      },
      {
        "id": "agent_004",
        "name": "Code Helper",
        "description": "Expert in programming, debugging, and code review",
        "model": "gemini-2.0-flash-exp"
      }
    ]
  },
  "id": 1
}
```

---

### Method: `process_text`

Send text to an AI agent and get a response.

**Request:**
```json
{
  "jsonrpc": "2.0",
  "method": "process_text",
  "params": {
    "agent_id": "agent_002",
    "user_text": "What is a blockchain?"
  },
  "id": 1
}
```

**Response:**
```json
{
  "jsonrpc": "2.0",
  "result": {
    "agent_id": "agent_002",
    "reply_text": "A blockchain is a distributed, immutable ledger that records transactions across multiple computers...",
    "metadata": {
      "model": "gemini-2.0-flash-exp",
      "tokens_used": 245,
      "processing_time_ms": 1523,
      "confidence": 0.95
    }
  },
  "id": 1
}
```

---

### Error Response

When an error occurs:

```json
{
  "jsonrpc": "2.0",
  "error": {
    "code": -32600,
    "message": "Invalid agent_id: agent_999"
  },
  "id": 1
}
```

## ğŸ”§ Testing with PowerShell

### Test Agent Listing

```powershell
$body = @{
    jsonrpc = "2.0"
    method = "list_agents"
    params = @{}
    id = 1
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:3000" `
  -Method POST `
  -ContentType "application/json" `
  -Body $body
```

### Test Text Processing

```powershell
$body = @{
    jsonrpc = "2.0"
    method = "process_text"
    params = @{
        agent_id = "agent_002"
        user_text = "Explain smart contracts"
    }
    id = 1
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:3000" `
  -Method POST `
  -ContentType "application/json" `
  -Body $body
```

### Test All Agents

```powershell
$agents = @("agent_001", "agent_002", "agent_003", "agent_004")
$question = "What can you help me with?"

foreach ($agent in $agents) {
    Write-Host "`n=== Testing $agent ===" -ForegroundColor Cyan
    
    $body = @{
        jsonrpc = "2.0"
        method = "process_text"
        params = @{
            agent_id = $agent
            user_text = $question
        }
        id = 1
    } | ConvertTo-Json
    
    $response = Invoke-RestMethod -Uri "http://localhost:3000" `
      -Method POST `
      -ContentType "application/json" `
      -Body $body
    
    Write-Host "Response: $($response.result.reply_text.Substring(0, 100))..." -ForegroundColor Green
    Write-Host "Tokens: $($response.result.metadata.tokens_used), Time: $($response.result.metadata.processing_time_ms)ms" -ForegroundColor Yellow
}
```

## ğŸ“Š Project Structure

```
mcp-server/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.rs         # All server code (routes, handlers, Gemini API)
â”œâ”€â”€ .env                # Environment configuration
â”œâ”€â”€ Cargo.toml          # Rust dependencies
â””â”€â”€ README.md           # This file
```

## ğŸ”§ Configuration Details

### Gemini API Settings

- **Endpoint:** `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent`
- **Authentication:** API key via `x-goog-api-key` header
- **Model:** `gemini-2.0-flash-exp` (latest Gemini model)
- **API Version:** `v1beta` (required for system_instruction support)

### System Instructions

Each agent has a unique system instruction that defines its behavior:

```rust
// Example: Web3 Expert
"You are a Web3 and blockchain technology expert. Provide detailed, 
accurate information about blockchain, cryptocurrency, DeFi, NFTs, 
smart contracts, and related technologies. Use technical terms when 
appropriate but explain them clearly."
```

## ğŸ› Troubleshooting

### Server won't start

**Error:** `GEMINI_API_KEY must be set in .env file`
- **Solution:** Create a `.env` file with your Gemini API key

**Error:** `Failed to bind to address`
- **Solution:** Port 3000 is in use. Kill the existing process or change the port in `main.rs`

### API Errors

**Error:** `400 Bad Request - Invalid JSON payload`
- **Solution:** Check your request format matches JSON-RPC 2.0 spec
- **Verify:** `jsonrpc: "2.0"`, `method`, `params`, and `id` fields are present

**Error:** `401 Unauthorized`
- **Solution:** Verify your Gemini API key is correct
- **Check:** Key is active at [Google AI Studio](https://aistudio.google.com/)

**Error:** `404 Not Found - model not found`
- **Solution:** Make sure you're using the v1beta endpoint
- **Verify:** URL includes `/v1beta/` not `/v1/`

**Error:** `Invalid agent_id`
- **Solution:** Use one of: `agent_001`, `agent_002`, `agent_003`, `agent_004`

### Performance Issues

**Slow responses:**
- **Normal:** First request may take 2-3 seconds (cold start)
- **Expected:** Subsequent requests typically 1-2 seconds
- **Solution:** If consistently slow, check your internet connection

**High token usage:**
- **Solution:** Shorter user_text = fewer tokens consumed
- **Monitor:** Check [Google AI Studio](https://aistudio.google.com/) for quota

## ğŸ“ˆ Response Metadata

Each response includes useful metadata:

```json
"metadata": {
  "model": "gemini-2.0-flash-exp",
  "tokens_used": 245,            // Total tokens (prompt + completion)
  "processing_time_ms": 1523,    // Server processing time
  "confidence": 0.95             // Currently hardcoded, future enhancement
}
```

## ğŸ”— Dependencies

- **axum** - Web framework
- **tokio** - Async runtime
- **reqwest** - HTTP client for Gemini API
- **serde** - JSON serialization
- **tower-http** - CORS support
- **tracing** - Structured logging

## ğŸ“ Development

### Building for Development

```powershell
cargo build
cargo run
```

### Running with Debug Logs

```powershell
$env:RUST_LOG="mcp_server=debug"
cargo run
```

### Adding a New Agent

Edit `src/main.rs` and add to the `get_agents()` function:

```rust
AgentInfo {
    id: "agent_005".to_string(),
    name: "Your Agent Name".to_string(),
    description: "What this agent does".to_string(),
    model: "gemini-2.0-flash-exp".to_string(),
}
```

Then add the system instruction in `handle_process_text()`:

```rust
"agent_005" => "Your custom system instruction here...",
```

## ğŸŒŸ Example Flow

1. **MCP API receives** user text: "What is DeFi?"
2. **MCP API sends JSON-RPC** to MCP Server with `agent_id: "agent_002"`
3. **MCP Server routes** to Web3 Expert agent
4. **System instruction applied**: "You are a Web3 expert..."
5. **Gemini API called** with user text + system instruction
6. **Gemini generates** detailed DeFi explanation
7. **MCP Server extracts** response text and metadata
8. **JSON-RPC response** returned to MCP API
9. **MCP API converts** to speech and sends to client

## ğŸ” Security Notes

- âš ï¸ **Never commit `.env`** with your API key to version control
- âœ… Add `.env` to `.gitignore`
- âœ… Use environment variables in production
- âœ… Rotate API keys periodically

## ğŸ“„ License

This project is part of the web3-valet system.

## ğŸ¤ Related Projects

- **mcp-api** - REST API frontend for this server
- **web3-minting** - NFT minting functionality

---

**Need help?** Enable debug logging with `RUST_LOG=debug` to see detailed request/response information.
